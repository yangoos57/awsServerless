{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KoNLPy 형태소 분석기 선정\n",
    "\n",
    "### 대상\n",
    "1. hannanum\n",
    "2. kkma\n",
    "3. okt\n",
    "\n",
    "### 선정 방법\n",
    "\n",
    "책 10권에 대해 각각 10개의 키워드 선정\n",
    "hannanum,kkma,okt 명사추출 기능으로 해당 키워드가 구분되는지 체크 \n",
    "\n",
    "### 도서목록\n",
    "1. 리액트를 다루는 기술 = The art of React : 실무에서 알아야 할 기술은 따로 있다!\n",
    "\n",
    "2. (Do it!) 장고 + 부트스트랩 파이썬 웹 개발의 정석 : 만들면서 배우는 웹 개발 A to Z\n",
    "3. 머신러닝 디자인 패턴 : 효율적인 머신러닝 파이프라인과 MLOps를 구축하는 30가지 디자인 패턴\n",
    "4. 핸즈온 머신러닝\n",
    "5. 파이썬을 이용한 데이터 분석의 정석 : 넘파이, 판다스, 맷플롯립과 실전 예제로 배우는\n",
    "6. 스파크 완벽 가이드 : 스파크를 활용한 빅데이터 처리와 분석의 모든 것\n",
    "7. 처음 시작하는 딥러닝\n",
    "8. 컴퓨터 사이언스 부트캠프 with 파이썬\n",
    "9. 케라스 창시자에게 배우는 딥러닝\n",
    "10. 처음 배우는 리액트 네이티브 크로스 플랫폼 앱 개발을 위한 실전 입문서\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum,Okt,Kkma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 비교에 사용 될 도서 10권 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookinfo = pd.read_csv('./data/bookInfo12.csv',encoding='cp949')\n",
    "testBooksISBN = [9791160508796,9791163032069,9791162244845,9791162242964,9791186710708,9791162241288,9791162243343,9791160504095,9791160505979,9791162243879]\n",
    "testBooks = bookinfo[bookinfo['col1'].isin(testBooksISBN)]\n",
    "han = Hannanum()\n",
    "\n",
    "\n",
    "def mergeListToString(wordList:list) -> str :\n",
    "    '''\n",
    "    wordList = item.astype(str).tolist()\n",
    "    item = pd.Series()\n",
    "    '''\n",
    "    str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    str_list = list(filter(None, str_list))\n",
    "    result :str = ' '.join(str_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookinfo = pd.read_csv('./data/keywordExtraction.csv',encoding='cp949')\n",
    "\n",
    "bookinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = books.iloc[1].tolist()\n",
    "def TFIDF(wordsList) :\n",
    "    from operator import itemgetter\n",
    "\n",
    "    # str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    # str_list = list(filter(None, str_list))\n",
    "\n",
    "    # han = Hannanum()\n",
    "    # word = ' '.join(str_list)\n",
    "    # konlpword = han.nouns(word)\n",
    "    # konlpword = ' '.join(konlpword)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sp_matrix = vectorizer.fit_transform(wordsList)\n",
    "\n",
    "    # a,b\n",
    "    a = np.array(vectorizer.get_feature_names_out())\n",
    "    b = sp_matrix.toarray()[0]\n",
    "    unique, counts = np.unique(b, return_counts=True)\n",
    "\n",
    "    ### Top 10 추출\n",
    "    k = 0\n",
    "    for num in range(1,100) :\n",
    "        if k < 10 :\n",
    "            k += counts[-num]\n",
    "        else :\n",
    "            break\n",
    "\n",
    "    result =[(a,b) for a,b in zip(a,b) if b >= unique[-num]]            \n",
    "    result = sorted(result,key=itemgetter(1),reverse=True)\n",
    "    return result\n",
    "\n",
    "wordsList=[mergeListToString(i[1]) for i in testBooks.iterrows()]\n",
    "konlpyWordsForTFIDF = list(map(lambda x : ' '.join(han.nouns(x)),wordsList ))\n",
    "k = TFIDF(konlpyWordsForTFIDF)\n",
    "TFIDFKeyword = list(map(lambda x : x[0],k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 5000개 적용 및 MultiProcessing 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "#도서별 모든 문장 하나로 합치기\n",
    "wordsList=[mergeListToString(i[1].astype(str).tolist()) for i in bookinfo.iterrows()] \n",
    "\n",
    " # 모든 문장 형태소 분석\n",
    "konlpyWordsForTFIDF = list(map(lambda x : ' '.join(han.nouns(x)),wordsList ))\n",
    "\n",
    "\n",
    "# 형태소 분석 결과 비지도학습\n",
    "vectorizer = TfidfVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(konlpyWordsForTFIDF) \n",
    "\n",
    "# 결과 추출\n",
    "a = np.array(vectorizer.get_feature_names_out()) # n개 키워드\n",
    "b = sp_matrix.toarray() ## 책 권수 만큼 array 생성(5237개). / 개별 array shape = shape(n,)\n",
    "\n",
    "# Keyword Top 10 추출\n",
    "result = []\n",
    "for arr in b :\n",
    "    unique, counts = np.unique(arr, return_counts=True)\n",
    "    ### Keyword Top 10 추출\n",
    "    k = 0\n",
    "    for num in range(1,100) :\n",
    "        if k < 10 :\n",
    "            k += counts[-num]\n",
    "        else :\n",
    "            break\n",
    "\n",
    "    try : \n",
    "        itemList =[(name,percent) for name,percent in zip(a,arr) if percent >= unique[-num]]            \n",
    "        itemList = sorted(itemList,key=itemgetter(1),reverse=True)\n",
    "        result.append(itemList)\n",
    "    except:\n",
    "        result.append(None)\n",
    "\n",
    "# 추출 결과를 column에 넣기 위한 전처리\n",
    "TFIDFKeyword =[]\n",
    "for item in result:\n",
    "    list1=[]\n",
    "    for x in item:\n",
    "        list1.append(x[0])\n",
    "    TFIDFKeyword.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['도커', '컨테이너', '실습', '쿠버네티스', '컴포즈', '매니페스트', '커맨드', '파드', '리눅스용', '설치', '실행']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 개별 단어에 Top 10 확보\n",
    "# TF-IDF 단점 : 매달 TF-IDF를 돌려야함. 비효율적이라 판단\n",
    "TFIDFKeyword[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeListToString(item:pd.Series) :\n",
    "    wordList = item.astype(str).tolist()\n",
    "    str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    str_list = list(filter(None, str_list))\n",
    "    result = ' '.join(str_list)\n",
    "    return result\n",
    "\n",
    "wordsList=[mergeListToString(i[1]) for i in bookinfo.iterrows()]\n",
    "print('Complete wordsList Load!!')\n",
    "konlpyWords = list(map(lambda x : han.nouns(x),wordsList ))\n",
    "embedding_model = Word2Vec(sentences=konlpyWords, window = 2, min_count=50, workers=7, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 vec 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 문장 들어오면 단어로 잘라주는 메소드\n",
    "def separateKeyword(words) :\n",
    "\n",
    "    if type(words) != str :\n",
    "        raise ValueError('str only possible')\n",
    "\n",
    "    k = re.findall(r'\\s|,|[^,\\s]+', words)\n",
    "    k = [i for i in k if i not in [',',' ']]\n",
    "    return k\n",
    "\n",
    "# 영문을 한글로 변환\n",
    "def transToHan(words:list) -> list:\n",
    "    EngToKorDict=pd.read_csv('./data/englist.csv',index_col=0)\n",
    "    result = []\n",
    "    for word in words :\n",
    "        enToko = EngToKorDict[EngToKorDict['0'].isin([word])]\n",
    "        if enToko.empty is not True :\n",
    "            result.extend(enToko['1'].tolist())\n",
    "        else :\n",
    "            result.append(word)\n",
    "        \n",
    "    return list(set(result))\n",
    "\n",
    "# 영문 문자 리스트 추출\n",
    "def findEng(text: str) -> str:\n",
    "    return re.findall(\"[a-zA-Z]+\", text)\n",
    "    \n",
    "# 한글 문자 리스트 추출\n",
    "def findHan(text: str) -> str:\n",
    "    return re.findall(u'[\\u3130-\\u318F\\uAC00-\\uD7A3]+', text)\n",
    "\n",
    "# 최종 \n",
    "def searchKeyword(word:list) :\n",
    "    val = separateKeyword(word)\n",
    "    keywordItems = transToHan(val)\n",
    "    engList = list(filter(lambda x : findEng(x),keywordItems))\n",
    "    hanList = list(filter(lambda x : findHan(x),keywordItems))\n",
    "    return dict(eng=engList,han=hanList,all=keywordItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def changeStringToList(strList) :\n",
    "    # strList = strList.replace(' ',', ')\n",
    "    # result = np.array(ast.literal_eval(strList))\n",
    "    return ast.literal_eval(strList)\n",
    "\n",
    "# 중복값 찾기\n",
    "def findOverlapNum(keywordsOfBook:list,keywordsWord2Vec):\n",
    "    return np.in1d(keywordsWord2Vec,keywordsOfBook)\n",
    "\n",
    "# 영문 검색 기능 추가\n",
    "def searchByKeywords(words:str) :\n",
    "    #검색 단어 한영 쪼개기\n",
    "    wordDict : dict = searchKeyword(words)\n",
    "\n",
    "    #한영 전부 있는 단어\n",
    "    allList = wordDict['all']\n",
    "    wordsLen = len(allList)\n",
    "\n",
    "    #한글만 추출\n",
    "    hanList = wordDict['han']\n",
    "\n",
    "    #model load(나중에 밖으로 뺴내야할 듯)\n",
    "    loaded_model = KeyedVectors.load_word2vec_format(\"booksTest1\")\n",
    "\n",
    "    #키워드 단어 불러오기 20개 추출\n",
    "    keywordsWord2Vec = loaded_model.most_similar(positive=hanList,topn=20)\n",
    "    Word2VecKeyword = list(map(lambda x : x[0],keywordsWord2Vec))\n",
    "\n",
    "    # 사용자가 검색한 단어와 합치기\n",
    "    allList.extend(Word2VecKeyword)\n",
    "\n",
    "    #추출한 키워드를 알고싶다면?\n",
    "    # print(allList)\n",
    "    \n",
    "    # 키워드 일치여부 확인하고 사용자 검색 단어에 가중치 넣기\n",
    "    val = np.array(list(map(lambda x : findOverlapNum(x,allList) ,result)))\n",
    "    df = pd.DataFrame(val)\n",
    "    for i in range(wordsLen) :\n",
    "        df[i] = df[i]*3\n",
    "        \n",
    "    return df.T.sum()\n",
    "\n",
    "# searchByKeywords 내에 포함되어야 할듯 \n",
    "dfRaw = pd.read_csv('./data/keywordExtraction2.csv',encoding='cp949',index_col=0)\n",
    "lists = dfRaw['keywords'].tolist()\n",
    "result = list(map(changeStringToList,lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도서명</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>sums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>(그림으로 공부하는)오라클 구조</td>\n",
       "      <td>9791188621996</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>그림으로 공부하는 오라클 구조</td>\n",
       "      <td>9791185890302</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>오라클로 배우는 데이터베이스 개론과 실습</td>\n",
       "      <td>9791156645023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>(전문가를 위한) 오라클 아키텍처 입문</td>\n",
       "      <td>9791188621101</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>(초보자를 위한) Oracle 12c :DBA 편</td>\n",
       "      <td>9791195942534</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>데이터베이스 인터널스 (분산 데이터베이스 시스템 심층 분석)</td>\n",
       "      <td>9791161754963</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>AWS 공인 솔류션스 아키텍트 올인원 스터디 가이드</td>\n",
       "      <td>9791161754482</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>깔끔한 파이썬 탄탄한 백엔드 :지금까지 없었던 백엔드 개발자를 위한 파이썬</td>\n",
       "      <td>9791186697757</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>(PostgreSQL로 시작하는)SQL 코딩입문=SQL Programming in ...</td>\n",
       "      <td>9788995447468</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>(주말에 끝내는)PHP 프로그래밍: 이틀 만에 개발 환경 구축부터 간단한 웹 애플리...</td>\n",
       "      <td>9788965401278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    도서명           ISBN sums\n",
       "3189                                 (그림으로 공부하는)오라클 구조   9791188621996    7\n",
       "5192                                   그림으로 공부하는 오라클 구조  9791185890302    7\n",
       "2881                             오라클로 배우는 데이터베이스 개론과 실습  9791156645023    7\n",
       "1645                             (전문가를 위한) 오라클 아키텍처 입문   9791188621101    7\n",
       "1734                       (초보자를 위한) Oracle 12c :DBA 편   9791195942534    7\n",
       "...                                                 ...            ...  ...\n",
       "2866                  데이터베이스 인터널스 (분산 데이터베이스 시스템 심층 분석)  9791161754963    3\n",
       "2874                       AWS 공인 솔류션스 아키텍트 올인원 스터디 가이드  9791161754482    3\n",
       "666          깔끔한 파이썬 탄탄한 백엔드 :지금까지 없었던 백엔드 개발자를 위한 파이썬   9791186697757    3\n",
       "2919  (PostgreSQL로 시작하는)SQL 코딩입문=SQL Programming in ...  9788995447468    3\n",
       "5234  (주말에 끝내는)PHP 프로그래밍: 이틀 만에 개발 환경 구축부터 간단한 웹 애플리...  9788965401278    3\n",
       "\n",
       "[301 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['keywords']의 String을 List로 반환\n",
    "\n",
    "\n",
    "kkkk=dfRaw.copy()\n",
    "userkeywords = '데이터베이스, 오라클'\n",
    "kkkk['sums'] = searchByKeywords(userkeywords)\n",
    "\n",
    "kkkk[kkkk['sums'] >= 3][['도서명','ISBN','sums']].sort_values(by='sums',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 이걸 SQL로 가능하게 만들어야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracKeywords(words:list) :\n",
    "    #검색 단어 한영 쪼개기\n",
    "    wordDict = searchKeyword(words)\n",
    "\n",
    "    #한영 전부 있는 단어\n",
    "    allList = wordDict['all']\n",
    "    wordsLen = len(allList)\n",
    "\n",
    "    #한글만 추출\n",
    "    hanList = wordDict['han']\n",
    "\n",
    "    #model load(나중에 밖으로 뺴내야할 듯)\n",
    "    loaded_model = KeyedVectors.load_word2vec_format(\"booksTest1\")\n",
    "\n",
    "    #키워드 단어 불러오기 20개 추출\n",
    "    keywordsWord2Vec = loaded_model.most_similar(positive=hanList,topn=20)\n",
    "    Word2VecKeyword = list(map(lambda x : x[0],keywordsWord2Vec))\n",
    "\n",
    "    # 사용자가 검색한 단어와 합치기\n",
    "    allList.extend(Word2VecKeyword)\n",
    "\n",
    "    return allList\n",
    "    \n",
    "userkeywords = '데이터베이스, sql'\n",
    "\n",
    "# extracKeywords(userkeywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv for sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = pd.read_csv('./data/keywordExtraction2.csv',encoding='cp949',index_col=0)\n",
    "\n",
    "# lists = csv['keywords'].tolist()\n",
    "# result = list(map(changeStringToList,lists))\n",
    "\n",
    "# k = pd.DataFrame(result)\n",
    "\n",
    "# asd = pd.merge(csv,k,how='left',left_index=True,right_index=True)\n",
    "# asd = asd.drop(columns='Unnamed: 0')\n",
    "# asd.to_csv('./data/keywordExtraction2ForSQL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도서명</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>주제분류번호</th>\n",
       "      <th>등록일자</th>\n",
       "      <th>이미지주소</th>\n",
       "      <th>keywords</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(그림과 실습으로 배우는) 도커 &amp; 쿠버네티스:개념과 작동 원리가 쏙쏙 이해되는 완...</td>\n",
       "      <td>오가사와라 시게타카 지음 ;심효섭 옮김</td>\n",
       "      <td>위키북스</td>\n",
       "      <td>9791158393038</td>\n",
       "      <td>005.1</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>['도커', '실습', '컨테이너', '쿠버네티스', '설치', '실행', '사용법...</td>\n",
       "      <td>도커</td>\n",
       "      <td>실습</td>\n",
       "      <td>...</td>\n",
       "      <td>dockerfile</td>\n",
       "      <td>ec</td>\n",
       "      <td>iso</td>\n",
       "      <td>minikube</td>\n",
       "      <td>nginx</td>\n",
       "      <td>ssh</td>\n",
       "      <td>ps</td>\n",
       "      <td>kubectl</td>\n",
       "      <td>commit</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>도메인 주도 설계 첫걸음:소프트웨어 아키텍처와 비즈니스 전략의 일치를 위한 핵심 패...</td>\n",
       "      <td>블라드 코노노프 지음;김민석,오창윤 옮김</td>\n",
       "      <td>위키북스</td>\n",
       "      <td>9791158393359</td>\n",
       "      <td>005.115</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>['도메인', '설계', '비즈니스', '컨텍스트', '모델', '바운디드', '결...</td>\n",
       "      <td>도메인</td>\n",
       "      <td>설계</td>\n",
       "      <td>...</td>\n",
       "      <td>variation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 도서명                      저자  \\\n",
       "0  (그림과 실습으로 배우는) 도커 & 쿠버네티스:개념과 작동 원리가 쏙쏙 이해되는 완...   오가사와라 시게타카 지음 ;심효섭 옮김   \n",
       "1  도메인 주도 설계 첫걸음:소프트웨어 아키텍처와 비즈니스 전략의 일치를 위한 핵심 패...  블라드 코노노프 지음;김민석,오창윤 옮김   \n",
       "\n",
       "    출판사           ISBN   주제분류번호        등록일자  \\\n",
       "0  위키북스  9791158393038    005.1  2022-06-22   \n",
       "1  위키북스  9791158393359  005.115  2022-06-22   \n",
       "\n",
       "                                               이미지주소  \\\n",
       "0  http://image.kyobobook.co.kr/images/book/large...   \n",
       "1  http://image.kyobobook.co.kr/images/book/large...   \n",
       "\n",
       "                                            keywords    0   1  ...  \\\n",
       "0  ['도커', '실습', '컨테이너', '쿠버네티스', '설치', '실행', '사용법...   도커  실습  ...   \n",
       "1  ['도메인', '설계', '비즈니스', '컨텍스트', '모델', '바운디드', '결...  도메인  설계  ...   \n",
       "\n",
       "           29   30   31        32     33   34   35       36      37    38  \n",
       "0  dockerfile   ec  iso  minikube  nginx  ssh   ps  kubectl  commit  nano  \n",
       "1   variation  NaN  NaN       NaN    NaN  NaN  NaN      NaN     NaN   NaN  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv('./data/keywordExtraction2ForSQL.csv',index_col=0)\n",
    "\n",
    "# csv = csv.drop(columns='39')\n",
    "# csv.to_csv('./data/keywordExtraction2ForSQL.csv')\n",
    "csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = np.vectorize(len)\n",
    "# for col in csv.columns :\n",
    "#     print(f'{col} : ',k(csv[col].astype(str).values).max())\n",
    "# ---\n",
    "# for i in range(39):\n",
    "#     print(f\"key{i} = models.CharField(max_length=20),\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "conn=pymysql.connect(host='localhost',port=int(3306),user='root',passwd='',db='dash_test')\n",
    "cursor = conn.cursor(pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Type</th>\n",
       "      <th>Null</th>\n",
       "      <th>Key</th>\n",
       "      <th>Default</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>bigint</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "      <td>None</td>\n",
       "      <td>auto_increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지역</td>\n",
       "      <td>varchar(5)</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISBN</td>\n",
       "      <td>bigint</td>\n",
       "      <td>NO</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Field        Type Null  Key Default           Extra\n",
       "0    id      bigint   NO  PRI    None  auto_increment\n",
       "1    지역  varchar(5)   NO         None                \n",
       "2  ISBN      bigint   NO  MUL    None                "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(' desc backend_dodomoalibinfo')\n",
    "result = cursor.fetchall()\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배운내용 저장(Notion에도 저장했음.)\n",
    "\n",
    "- WHERE을 사용할 때 Value가 String일 경우 따옴표를 붙여줘야 정상작동한다.\n",
    "\n",
    "-  isin과 같음 : FIND_IN_SET(column명, 변수) * 변수 = 'a,b,c' 형태여야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>지역</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>영등포</td>\n",
       "      <td>9788970936208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>영등포</td>\n",
       "      <td>9788970505411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>영등포</td>\n",
       "      <td>9791197119927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   지역           ISBN\n",
       "0   1  영등포  9788970936208\n",
       "1   2  영등포  9788970505411\n",
       "2   3  영등포  9791197119927"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = \"영등포,동작,양천\"\n",
    "cursor.execute(f'SELECT * FROM backend_dodomoalibinfo WHERE FIND_IN_SET(지역,\"{var}\") >0')\n",
    "result = cursor.fetchall()\n",
    "pd.DataFrame(result).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9788934961772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9788980783106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9788934949541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9791165219659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9788931556698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>9788956747842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>9791162240861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>9791158740405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>9791162241042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>9791162240403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN\n",
       "0     9788934961772\n",
       "1     9788980783106\n",
       "2     9788934949541\n",
       "3     9791165219659\n",
       "4     9788931556698\n",
       "...             ...\n",
       "1023  9788956747842\n",
       "1024  9791162240861\n",
       "1025  9791158740405\n",
       "1026  9791162241042\n",
       "1027  9791162240403\n",
       "\n",
       "[1028 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = \"양천\"\n",
    "cursor.execute(f'SELECT ISBN FROM backend_dodomoalibinfo WHERE FIND_IN_SET(지역,\"{var}\") >0')\n",
    "result = cursor.fetchall()\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHERE 순서에 따른 JOIN 속도 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN WHERE FIND_IN_SET\n",
    "# 18 ms ± 538 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "var = \"양천,강서\"\n",
    "cursor.execute(f'''SELECT book.*, lib.지역 FROM backend_dodomoabookinfo AS book\n",
    "                   LEFT JOIN backend_dodomoalibinfo AS lib\n",
    "                   ON book.ISBN = lib.ISBN\n",
    "                   where FIND_IN_SET(지역,\"{var}\") > 0''')\n",
    "result = cursor.fetchall()\n",
    "a = pd.DataFrame(result).drop_duplicates(subset=['id','지역'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.7 ms ± 409 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# JOIN WHERE IN\n",
    "# 15.7 ms ± 538 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "var = \"양천\"\n",
    "cursor.execute(f'''SELECT book.*, lib.지역 FROM backend_dodomoabookinfo AS book\n",
    "                   LEFT JOIN backend_dodomoalibinfo AS lib\n",
    "                   ON book.ISBN = lib.ISBN\n",
    "                   where 지역 in (\"{var}\")''' )\n",
    "result = cursor.fetchall()\n",
    "a = pd.DataFrame(result).drop_duplicates(subset=['id','지역'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN On\n",
    "# 54.1 ms ± 391 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) \n",
    "#### and를 넣으니 FIND_IN_SET이 적용되지 않음.\n",
    "var = \"양천\"\n",
    "cursor.execute(f''' SELECT book.*, lib.지역 FROM backend_dodomoabookinfo AS book\n",
    "                   LEFT JOIN backend_dodomoalibinfo AS lib\n",
    "                   ON (book.ISBN = lib.ISBN\n",
    "                   AND FIND_IN_SET(지역,\"{var}\") > 0)''')\n",
    "result = cursor.fetchall()\n",
    "a = pd.DataFrame(result).drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>도서명</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>주제분류번호</th>\n",
       "      <th>등록일자</th>\n",
       "      <th>이미지주소</th>\n",
       "      <th>지역</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.788935e+12</td>\n",
       "      <td>전길남, 연결의 탄생: 한국 인터넷의 개척자 전길남 이야기</td>\n",
       "      <td>구본권 지음</td>\n",
       "      <td>김영사</td>\n",
       "      <td>004.58</td>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>양천</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4306.0</td>\n",
       "      <td>9.788981e+12</td>\n",
       "      <td>(Python™으로 배우는) OpenCV 프로그래밍 =Image Processing...</td>\n",
       "      <td>김동근 지음</td>\n",
       "      <td>KM(가메출판사)</td>\n",
       "      <td>004.77</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>양천</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          ISBN                                                도서명  \\\n",
       "0     8.0  9.788935e+12                   전길남, 연결의 탄생: 한국 인터넷의 개척자 전길남 이야기   \n",
       "1  4306.0  9.788981e+12  (Python™으로 배우는) OpenCV 프로그래밍 =Image Processing...   \n",
       "\n",
       "       저자        출판사  주제분류번호        등록일자  \\\n",
       "0  구본권 지음        김영사  004.58  2022-06-07   \n",
       "1  김동근 지음  KM(가메출판사)  004.77  2022-06-14   \n",
       "\n",
       "                                               이미지주소  지역  \n",
       "0  http://image.kyobobook.co.kr/images/book/large...  양천  \n",
       "1  http://image.kyobobook.co.kr/images/book/large...  양천  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WHERE 먼저 그다음 Join\n",
    "# 15 ms ± 331 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "var = \"양천\"\n",
    "cursor.execute(f''' SELECT book.*, lib.지역 FROM (SELECT * FROM backend_dodomoalibinfo where FIND_IN_SET(지역,\"{var}\") > 0) AS lib \n",
    "                   LEFT JOIN  backend_dodomoabookinfo AS book\n",
    "                   ON book.ISBN = lib.ISBN\n",
    "                   ''')\n",
    "result = cursor.fetchall()\n",
    "a = pd.DataFrame(result).drop_duplicates(subset='id')\n",
    "a.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyword 찾아서 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeywords(words:str) :\n",
    "    #검색 단어 한영 쪼개기\n",
    "    wordDict : dict = searchKeyword(words)\n",
    "\n",
    "    #한영 전부 있는 단어\n",
    "    allList = wordDict['all']\n",
    "    wordsLen = len(allList)\n",
    "\n",
    "    #한글만 추출\n",
    "    hanList = wordDict['han']\n",
    "\n",
    "    #model load(나중에 밖으로 뺴내야할 듯)\n",
    "    loaded_model = KeyedVectors.load_word2vec_format(\"booksTest1\")\n",
    "\n",
    "    #키워드 단어 불러오기 20개 추출\n",
    "    keywordsWord2Vec = loaded_model.most_similar(positive=hanList,topn=20)\n",
    "    Word2VecKeyword = list(map(lambda x : x[0],keywordsWord2Vec))\n",
    "\n",
    "    # 사용자가 검색한 단어와 합치기\n",
    "    allList.extend(Word2VecKeyword)\n",
    "    keywords = ' '.join(allList)\n",
    "    # regex = keywords.replace(' ','|')\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9791158393038</td>\n",
       "      <td>도커 실습 컨테이너 쿠버네티스 설치 실행 사용법 컴포즈 이미지 작성 커맨드 매니페스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2908</td>\n",
       "      <td>9791190014953</td>\n",
       "      <td>리눅스 해킹 취약점 도커 실습 환경 칼리 코드 분석 명령어 테스트 기초 활용 루비 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3200</td>\n",
       "      <td>9791161755786</td>\n",
       "      <td>쿠버네티스 애플리케이션 데브옵스 실습 구성 소개 관리 클러스터 확장 클라우드 업데이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           ISBN                                            keyword\n",
       "0     1  9791158393038  도커 실습 컨테이너 쿠버네티스 설치 실행 사용법 컴포즈 이미지 작성 커맨드 매니페스...\n",
       "1  2908  9791190014953  리눅스 해킹 취약점 도커 실습 환경 칼리 코드 분석 명령어 테스트 기초 활용 루비 ...\n",
       "2  3200  9791161755786  쿠버네티스 애플리케이션 데브옵스 실습 구성 소개 관리 클러스터 확장 클라우드 업데이..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = '도커'\n",
    "cursor.execute(f'''SELECT * FROM backend_dodomoakeyword2 where keyword like \"%도커%\" and keyword like \"%실습%\"  ''') \n",
    "result = cursor.fetchall()\n",
    "pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>key0</th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>key3</th>\n",
       "      <th>key4</th>\n",
       "      <th>key5</th>\n",
       "      <th>key6</th>\n",
       "      <th>key7</th>\n",
       "      <th>...</th>\n",
       "      <th>key29</th>\n",
       "      <th>key30</th>\n",
       "      <th>key31</th>\n",
       "      <th>key32</th>\n",
       "      <th>key33</th>\n",
       "      <th>key34</th>\n",
       "      <th>key35</th>\n",
       "      <th>key36</th>\n",
       "      <th>key37</th>\n",
       "      <th>key38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9791158393038</td>\n",
       "      <td>도커</td>\n",
       "      <td>실습</td>\n",
       "      <td>컨테이너</td>\n",
       "      <td>쿠버네티스</td>\n",
       "      <td>설치</td>\n",
       "      <td>실행</td>\n",
       "      <td>사용법</td>\n",
       "      <td>컴포즈</td>\n",
       "      <td>...</td>\n",
       "      <td>dockerfile</td>\n",
       "      <td>ec</td>\n",
       "      <td>iso</td>\n",
       "      <td>minikube</td>\n",
       "      <td>nginx</td>\n",
       "      <td>ssh</td>\n",
       "      <td>ps</td>\n",
       "      <td>kubectl</td>\n",
       "      <td>commit</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           ISBN key0 key1  key2   key3 key4 key5 key6 key7  ...  \\\n",
       "0   1  9791158393038   도커   실습  컨테이너  쿠버네티스   설치   실행  사용법  컴포즈  ...   \n",
       "\n",
       "        key29 key30 key31     key32  key33 key34 key35    key36   key37 key38  \n",
       "0  dockerfile    ec   iso  minikube  nginx   ssh    ps  kubectl  commit  nano  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = '도커'\n",
    "cursor.execute(f'''SELECT * FROM backend_dodomoakeyword where FIND_IN_SET(key0,\"{var}\") > 0 limit 1 ''')\n",
    "result = cursor.fetchall()\n",
    "pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords, regex, wordsLen = extractKeywords('데이터베이스,sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cursor.execute(f''' SELECT \n",
    "ISBN,\n",
    "(CHAR_LENGTH(`keyword`) - CHAR_LENGTH(REGEXP_REPLACE(`keyword`, '{regex}', '')))\n",
    " / (CHAR_LENGTH('{keywords}') - {wordsLen}) AS rate\n",
    "FROM backend_dodomoakeyword2 \n",
    "WHERE match(keyword) against(\"{keywords}\")''')\n",
    "\n",
    "result = cursor.fetchall()\n",
    "k = pd.DataFrame(result).sort_values(by='rate', ascending=False)\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = '양천,강서'\n",
    "keywords = extractKeywords('데이터베이스,sql,mysql')\n",
    "#11.5 ms ± 189 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "cursor.execute(f'''\n",
    "      SELECT * \n",
    "      FROM (SELECT keyword2.ISBN, GROUP_CONCAT(lib.지역) as 지역\n",
    "\n",
    "            -- 지역을 먼저 골라서 필요한 lib 만 추출 \n",
    "            FROM (SELECT * \n",
    "                  FROM backend_dodomoalibinfo \n",
    "                  where FIND_IN_SET(지역,\"{var}\") > 0) AS lib \n",
    "\n",
    "            -- 첫번째 LEFT JOIN \n",
    "            LEFT JOIN backend_dodomoakeyword2 AS keyword2 \n",
    "            ON keyword2.ISBN = lib.ISBN\n",
    "            where match(keyword) against(\"{keywords}\")\n",
    "            GROUP BY keyword2.ISBN) AS sortedISBN\n",
    "\n",
    "      -- 두번째 LEFT JOIN \n",
    "      LEFT JOIN backend_dodomoabookinfo AS book\n",
    "      ON book.ISBN = sortedISBN.ISBN '''\n",
    "\n",
    "      )\n",
    "result = cursor.fetchall()\n",
    "a = pd.DataFrame(result)\n",
    "\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도서명</th>\n",
       "      <th>저자</th>\n",
       "      <th>지역모음</th>\n",
       "      <th>주제분류번호</th>\n",
       "      <th>이미지주소</th>\n",
       "      <th>sum</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(텐서플로와 머신러닝으로 시작하는) 자연어 처리 :로지스틱 회귀부터 트랜스포머 챗봇까지</td>\n",
       "      <td>전창욱,최태균,조중현 지음</td>\n",
       "      <td>양천</td>\n",
       "      <td>004.73</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>4</td>\n",
       "      <td>처리 자연어 모델 데이터 텍스트 분류 소개 기반 문제 사이킷런 활용 딥러닝 유사 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>한국어 임베딩</td>\n",
       "      <td>이기창</td>\n",
       "      <td>양천</td>\n",
       "      <td>004.735</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>4</td>\n",
       "      <td>임베딩 모델 자연어 학습 단어 한국어 수준 처리 문장 기법 데이터 의미 네트워크 튜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김기현의 자연어 처리 딥러닝 캠프</td>\n",
       "      <td>김기현 (지은이)</td>\n",
       "      <td>양천</td>\n",
       "      <td>004.73</td>\n",
       "      <td>http://image.kyobobook.co.kr/images/book/large...</td>\n",
       "      <td>4</td>\n",
       "      <td>자연어 처리 활용 딥러닝 설명 기술 내용 저자 언어 경험 머신러닝 강화학습 이론 신...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 도서명              저자 지역모음  \\\n",
       "0  (텐서플로와 머신러닝으로 시작하는) 자연어 처리 :로지스틱 회귀부터 트랜스포머 챗봇까지   전창욱,최태균,조중현 지음   양천   \n",
       "1                                            한국어 임베딩             이기창   양천   \n",
       "2                                 김기현의 자연어 처리 딥러닝 캠프       김기현 (지은이)   양천   \n",
       "\n",
       "    주제분류번호                                              이미지주소  sum  \\\n",
       "0   004.73  http://image.kyobobook.co.kr/images/book/large...    4   \n",
       "1  004.735  http://image.kyobobook.co.kr/images/book/large...    4   \n",
       "2   004.73  http://image.kyobobook.co.kr/images/book/large...    4   \n",
       "\n",
       "                                             keyword  \n",
       "0  처리 자연어 모델 데이터 텍스트 분류 소개 기반 문제 사이킷런 활용 딥러닝 유사 분...  \n",
       "1  임베딩 모델 자연어 학습 단어 한국어 수준 처리 문장 기법 데이터 의미 네트워크 튜...  \n",
       "2  자연어 처리 활용 딥러닝 설명 기술 내용 저자 언어 경험 머신러닝 강화학습 이론 신...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 함수들 \n",
    "import ast\n",
    "from curses.ascii import isalpha\n",
    "import re\n",
    "import pymysql\n",
    "\n",
    "conn=pymysql.connect(host='localhost',port=int(3306),user='root',passwd='',db='dash_test')\n",
    "cursor = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "# 문장 들어오면 단어로 잘라주는 메소드\n",
    "def separateKeyword(words) :\n",
    "\n",
    "    if type(words) != str :\n",
    "        raise ValueError('str only possible')\n",
    "\n",
    "    k = re.findall(r'\\s|,|[^,\\s]+', words)\n",
    "    k = [i for i in k if i not in [',',' ']]\n",
    "    return k\n",
    "\n",
    "# 영문을 한글로 변환\n",
    "def transToHan(words:list) -> list:\n",
    "    EngToKorDict=pd.read_csv('./data/englist.csv',index_col=0)\n",
    "    result = []\n",
    "    for word in words :\n",
    "        enToko = EngToKorDict[EngToKorDict['0'].isin([word])]\n",
    "        if enToko.empty is not True :\n",
    "            result.extend(enToko['1'].tolist())\n",
    "        else :\n",
    "            result.append(word)\n",
    "        \n",
    "    return list(set(result))\n",
    "\n",
    "# 영문 문자 리스트 추출\n",
    "def findEng(text: str) -> str:\n",
    "    return re.findall(\"[a-zA-Z]+\", text)\n",
    "    \n",
    "# 한글 문자 리스트 추출\n",
    "def findHan(text: str) -> str:\n",
    "    return re.findall(u'[\\u3130-\\u318F\\uAC00-\\uD7A3]+', text)\n",
    "\n",
    "# 최종 \n",
    "def searchKeyword(word:list) :\n",
    "    val = separateKeyword(word)\n",
    "    keywordItems = transToHan(val)\n",
    "    engList = list(filter(lambda x : findEng(x),keywordItems))\n",
    "    hanList = list(filter(lambda x : findHan(x),keywordItems))\n",
    "    return dict(eng=engList,han=hanList,all=keywordItems)\n",
    "\n",
    "# 중복값 찾기\n",
    "def findOverlapNum(keywordsOfBook:list,keywordsWord2Vec):\n",
    "    return np.in1d(keywordsWord2Vec,keywordsOfBook)\n",
    "\n",
    "def extractKeywords(words:str) -> list :\n",
    "    \n",
    "    #검색 단어 한영 쪼개기\n",
    "    wordDict : dict = searchKeyword(words)\n",
    "\n",
    "    #한영 전부 있는 단어\n",
    "    allList = wordDict['all']\n",
    "\n",
    "    #한글만 추출\n",
    "    hanList = wordDict['han']\n",
    "    if len(hanList) > 0 : \n",
    "        #model load(나중에 밖으로 뺴내야할 듯)\n",
    "        loaded_model = KeyedVectors.load_word2vec_format(\"w2v\")\n",
    "\n",
    "        #키워드 단어 불러오기 20개 추출\n",
    "        keywordsWord2Vec = loaded_model.most_similar(positive=hanList,topn=20)\n",
    "        Word2VecKeyword = list(map(lambda x : x[0],keywordsWord2Vec))\n",
    "\n",
    "        # 사용자가 검색한 단어와 합치기\n",
    "        allList.extend(Word2VecKeyword)\n",
    "\n",
    "    # String으로 변환\n",
    "    keywords = ' '.join(allList)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "\n",
    "### 1. frontend로부터 해당 자료를 받음\n",
    "\n",
    "# var = '양천,강서,강남,강동'\n",
    "var = '양천'\n",
    "userwords = 'bert'\n",
    "\n",
    "### 2. userwords 외에 추가적인 keyword 추출\n",
    "keywords= extractKeywords(userwords)\n",
    "print(keywords)\n",
    "\n",
    "# 3. 사용자가 선택한 조건 및 키워드로 검색 결과 추출\n",
    "\n",
    "## Group By를 더 빨리해서 검색해야하는 ISBN 개수를 줄였는데 위에있는 쿼리보다 보다 속도가 느림.\n",
    "# 16.7 ms ± 868 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "cursor.execute(f'''\n",
    "      SELECT * \n",
    "      FROM (\n",
    "            SELECT keyword2.ISBN, keyword2.keyword, lib.지역모음\n",
    "\n",
    "            -- 사용자가 선택한 도서관의 도서 정보를 불러온다.\n",
    "            FROM (SELECT ISBN, GROUP_CONCAT(지역) AS 지역모음\n",
    "                  FROM backend_dodomoalibinfo \n",
    "                  where FIND_IN_SET(지역,\"{var}\") > 0\n",
    "                  GROUP BY ISBN ) AS lib \n",
    "\n",
    "            -- 첫번째 LEFT JOIN\n",
    "            -- keyword가 포함된 ISBN만 추출 \n",
    "            LEFT JOIN backend_dodomoakeyword2 AS keyword2 \n",
    "            ON keyword2.ISBN = lib.ISBN\n",
    "            where match(keyword) against(\"{keywords}\")\n",
    "            ) AS sortedISBN\n",
    "\n",
    "      -- 두번째 LEFT JOIN\n",
    "      -- 추출된 도서의 도서정보(제목, 저자, 청구기호 등) 가져오기\n",
    "      LEFT JOIN backend_dodomoabookinfo AS book\n",
    "      ON book.ISBN = sortedISBN.ISBN\n",
    "      \n",
    "      ''')\n",
    "\n",
    "\n",
    "result = cursor.fetchall()\n",
    "result = pd.DataFrame(result)\n",
    "\n",
    "### 4. TOP 50개 선정\n",
    "\n",
    "## 사용자가 직접 검색한 단어 개수\n",
    "wordsLen = len(userwords.split(',')) \n",
    "\n",
    "## keyword str to list\n",
    "keyList = list(map(lambda x : x.split(' '), result['keyword']))\n",
    "\n",
    "## 추출한 keyword str to list\n",
    "allList = keywords.split(' ')\n",
    "\n",
    "## 추출한 키워드와 일치 개수 찾기 & 유저가 검색한 것 3배 가중\n",
    "val = np.array(list(map(lambda x : findOverlapNum(x,allList) ,keyList)))\n",
    "df = pd.DataFrame(val)\n",
    "for i in range(wordsLen) :\n",
    "    df[i] = df[i]*4\n",
    "result['sum'] = df.T.sum()\n",
    "\n",
    "finish = result.sort_values(by='sum',ascending=False)[:50]\n",
    "\n",
    "finish = finish[['도서명','저자','지역모음','주제분류번호','이미지주소','sum','keyword']]\n",
    "finish.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eng': ['learning', 'deep'], 'han': [], 'all': ['learning', 'deep']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userwords = 'deep learning'\n",
    "### 2. userwords 외에 추가적인 keyword 추출\n",
    "# keywords = extractKeywords(userwords)\n",
    "\n",
    "# keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
