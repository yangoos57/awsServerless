{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from components import scraping, modeling\n",
    "# key = modeling.keywordExtractor(dir='data/preprocess/eng_han.csv')\n",
    "keyword = pd.read_parquet('data/update/extracted_keywords.parquet')\n",
    "book_info = pd.read_parquet('data/local_data/backup/book_info.parquet')\n",
    "\n",
    "def add_None(lst) :\n",
    "    # pad도 notion에 넣기 \n",
    "    pad_length=20-len(lst)\n",
    "    return np.pad(np.array(lst),(0,pad_length),'constant', constant_values=('None'))\n",
    "\n",
    "book_keyword = np.row_stack(list(map(add_None,keyword.keyword.values)))\n",
    "isbn_list = keyword['isbn13'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import Deployment\n",
    "lib_book= pd.read_parquet('data/update/lib_books.parquet')\n",
    "lib_dict = Deployment().lib_codes\n",
    "lib_book['lib_code'] = lib_book['lib_code'].apply(lambda x : lib_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "\n",
    "model = keyedvectors.load_word2vec_format('data/update/w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import * \n",
    "user_search = ['파이썬']\n",
    "\n",
    "def extract_recommand_book_isbn(user_search:List[str]) -> List[str] : \n",
    "    # extract recommand_keyword\n",
    "    recommand_keyword = model.most_similar(positive=user_search,topn=15)\n",
    "    np_recommand_keyword = np.array(list(map(lambda x : x[0],recommand_keyword)))\n",
    "\n",
    "    # calculate top_k_idx\n",
    "    user_point = np.isin(book_keyword,np.array(user_search)).sum(axis=1)\n",
    "    recommand_point = np.isin(book_keyword,np_recommand_keyword).sum(axis=1)\n",
    "    total_point = (user_point * 3) + recommand_point\n",
    "    top_k_idx = np.argsort(total_point)[::-1][:50]\n",
    "\n",
    "    return isbn_list[top_k_idx]\n",
    "\n",
    "# 281us\n",
    "# result = book_info.iloc[pd.Index(book_info['ISBN']).get_indexer(sorted_isbn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9791162241905', '9791161756233', '9788957175231', '9791157832361',\n",
       "       '9791162242414', '9791191198010', '9791161753324', '9791165366407',\n",
       "       '9791197347023', '9791192373126', '9788968480478', '9791158391225',\n",
       "       '9791162245569', '9791185578798', '9788970505220', '9791190283700',\n",
       "       '9791158391881', '9791197888014', '9791196440923', '9791158393571',\n",
       "       '9791158392260', '9791161340210', '9791161750910', '9788970505558',\n",
       "       '9791161752136', '9791162244210', '9791127453497', '9788960778535',\n",
       "       '9791160507812', '9791192038049', '9791162245545', '9791156006978',\n",
       "       '9791165211639', '9791158392284', '9791186710678', '9791160505979',\n",
       "       '9788970938424', '9791155505649', '9791190014281', '9791160503371',\n",
       "       '9791185578729', '9791158392390', '9791158391836', '9788956748573',\n",
       "       '9788931555684', '9791165920722', '9791162245415', '9791158391126',\n",
       "       '9791158391522', '9788970509402'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_recommand_book_isbn(user_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a(36.9ms) => b(22.1ms)\n",
    "a = (np_recommand_keyword==book_keyword[...,None]).any(axis=1).sum(axis=1)\n",
    "b = np.isin(book_keyword,np_recommand_keyword).sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
