{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from components import scraping, modeling\n",
    "# key = modeling.keywordExtractor(dir='data/preprocess/eng_han.csv')\n",
    "keyword = pd.read_parquet('data/update/extracted_keywords.parquet')\n",
    "book_info = pd.read_parquet('data/local_data/backup/book_info.parquet')\n",
    "\n",
    "def add_None(lst) :\n",
    "    # pad도 notion에 넣기 \n",
    "    pad_length=20-len(lst)\n",
    "    return np.pad(np.array(lst),(0,pad_length),'constant', constant_values=('None'))\n",
    "\n",
    "book_keyword = np.row_stack(list(map(add_None,keyword.keyword.values)))\n",
    "isbn_list = keyword['isbn13'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import Deployment\n",
    "lib_book= pd.read_parquet('data/update/lib_books.parquet')\n",
    "lib_dict = Deployment().lib_codes\n",
    "lib_book['lib_code'] = lib_book['lib_code'].apply(lambda x : lib_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "\n",
    "model = keyedvectors.load_word2vec_format('data/update/w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import * \n",
    "user_search = ['파이썬']\n",
    "\n",
    "def extract_recommand_book_isbn(user_search:List[str]) -> List[str] : \n",
    "    # extract recommand_keyword\n",
    "    recommand_keyword = model.most_similar(positive=user_search,topn=15)\n",
    "    np_recommand_keyword = np.array(list(map(lambda x : x[0],recommand_keyword)))\n",
    "\n",
    "    # calculate top_k_idx\n",
    "    user_point = np.isin(book_keyword,np.array(user_search)).sum(axis=1)\n",
    "    recommand_point = np.isin(book_keyword,np_recommand_keyword).sum(axis=1)\n",
    "    total_point = (user_point * 3) + recommand_point\n",
    "    top_k_idx = np.argsort(total_point)[::-1][:50]\n",
    "\n",
    "    return isbn_list[top_k_idx]\n",
    "\n",
    "# 281us\n",
    "# result = book_info.iloc[pd.Index(book_info['ISBN']).get_indexer(sorted_isbn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_recommand_book_isbn(user_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a(36.9ms) => b(22.1ms)\n",
    "a = (np_recommand_keyword==book_keyword[...,None]).any(axis=1).sum(axis=1)\n",
    "b = np.isin(book_keyword,np_recommand_keyword).sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
